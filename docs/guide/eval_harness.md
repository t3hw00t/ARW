---
title: Evaluation Harness
---

# Evaluation Harness
Updated: 2025-09-12
Type: How‑to

Purpose
- Safely evolve models, recipes, tools, and policies; measure if changes helped.

Components
- Golden tasks and datasets per project.
- A/B(/n) across model/recipe/policy.
- Metrics: task success, tool success, retrieval diversity, latency, cost.

Flow
- Define a benchmark set → run variants → compare metrics → gate promotions.

Artifacts
- Store results as artifacts with provenance; export CSV/JSON reports.

See also: Artifacts & Provenance, Runtime Matrix, Cost & Quotas.
