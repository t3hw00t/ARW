#!/usr/bin/env python3
import json, pathlib, datetime, subprocess, os, re, sys

ROOT = pathlib.Path(__file__).resolve().parents[1]
DATA_JSON = ROOT / "interfaces" / "system_components.json"
OUT_MD = ROOT / "docs" / "reference" / "system_components.md"
FEATURES_JSON = ROOT / "interfaces" / "features.json"
TOPICS_RS = ROOT / "crates" / "arw-topics" / "src" / "lib.rs"

INTERFACE_LABELS = {
    "http": "HTTP",
    "tools": "Tools",
    "env": "Environment",
    "config": "Config",
    "query": "Query",
    "topics": "Topics",
    "storage": "Storage",
    "read_models": "Read-models"
}


def github_blob_base() -> str:
    env_base = os.getenv("REPO_BLOB_BASE")
    if env_base:
        return env_base.rstrip("/") + "/"
    try:
        remote = subprocess.check_output(["git", "config", "--get", "remote.origin.url"], text=True).strip()
        m = re.search(r"github\\.com[:/]{1,2}([^/]+)/([^/.]+)", remote)
        if m:
            owner, repo = m.group(1), m.group(2)
            return f"https://github.com/{owner}/{repo}/blob/main/"
    except Exception:
        pass
    return "https://github.com/t3hw00t/ARW/blob/main/"


def _stable_now_timestamp(paths):
    try:
        args = ["git", "log", "-1", "--format=%cI", "--"] + [str(p) for p in paths if p]
        ts = subprocess.check_output(args, text=True).strip()
        if ts:
            return ts.replace("+00:00", "Z")
    except Exception:
        pass
    env_ts = os.getenv("REPRO_NOW")
    if env_ts:
        return env_ts
    return datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc).isoformat(timespec="seconds").replace("+00:00", "Z")


def check_paths_exist(paths):
    missing = []
    for p in paths:
        pp = ROOT / p
        if not pp.exists():
            missing.append(p)
    return missing


def load_components():
    with DATA_JSON.open("r", encoding="utf-8") as fh:
        return json.load(fh)


def load_features():
    if not FEATURES_JSON.exists():
        return {}
    with FEATURES_JSON.open("r", encoding="utf-8") as fh:
        return json.load(fh)


def parse_topics_rs():
    if not TOPICS_RS.exists():
        return set()
    text = TOPICS_RS.read_text(encoding="utf-8", errors="ignore")
    vals = set(re.findall(r'"([^"]+)"', text))
    vals.add("state.read.model.patch")
    return vals


def merge_lists(*lists):
    seen = set()
    merged = []
    for lst in lists:
        for item in lst or []:
            if item not in seen:
                merged.append(item)
                seen.add(item)
    return merged


def merge_scope(feature_scope, component_scope):
    scope = {}
    if feature_scope:
        scope.update({k: v for k, v in feature_scope.items() if v})
    if component_scope:
        scope.update({k: v for k, v in component_scope.items() if v})
    return scope


def slugify(name: str) -> str:
    s = name.strip().lower()
    s = re.sub(r"[^a-z0-9]+", "-", s)
    return s.strip("-")


def render(doc, features, known_topics):
    components = doc.get("components", [])
    base = github_blob_base()
    now = _stable_now_timestamp([DATA_JSON, FEATURES_JSON])
    id_to_name = {c.get("id"): c.get("name") for c in components}
    feature_map = {f.get("id"): f for f in features.get("features", [])}
    feature_to_component_ids = {}
    for comp in components:
        fid = comp.get("feature_id")
        if fid:
            feature_to_component_ids.setdefault(fid, []).append(comp.get("id"))
    missing_features = []
    lines = []
    lines.append("---")
    lines.append("title: System Components")
    lines.append("---\n")
    lines.append("<!-- generated by scripts/gen_system_components.py; do not edit by hand -->")
    lines.append(f"\n_Last updated: {now}_\n")
    lines.append("# System Components\n")
    lines.append(
        f"This page is generated from [interfaces/system_components.json]({base}interfaces/system_components.json) "
        f"and reconciled with [interfaces/features.json]({base}interfaces/features.json) plus topic constants in "
        f"[`crates/arw-topics`]({base}crates/arw-topics/src/lib.rs).\n"
    )

    for comp in components:
        name = comp.get("name", comp.get("id", "(unknown)"))
        desc = comp.get("description", "")
        feature = None
        if comp.get("feature_id"):
            feature = feature_map.get(comp["feature_id"])
            if feature is None:
                missing_features.append(comp["feature_id"])
        lines.append(f"## {name}\n")
        if desc:
            lines.append(desc + "\n")
        if feature:
            feat_name = feature.get("name", comp.get("feature_id"))
            slug = slugify(feat_name)
            lines.append(
                f"- Feature: [{feat_name}](feature_matrix.md#{slug}) ({feature.get('tier', 'unknown tier')})"
            )
        category = comp.get("category")
        scope = merge_scope(feature.get("scope") if feature else {}, comp.get("scope"))
        scope_parts = []
        if feature and feature.get("tier"):
            scope_parts.append(feature.get("tier"))
        scope_parts.extend(
            part
            for part in [scope.get("surface"), scope.get("audience"), scope.get("layer"), scope.get("maturity")]
            if part
        )
        scope_parts = [p for p in scope_parts if p]
        if category:
            lines.append(f"- Category: {category}")
        if scope_parts:
            lines.append(f"- Scope: {' / '.join(scope_parts)}")
        owner = comp.get("owner") or (feature.get("owner") if feature else None)
        if owner:
            lines.append(f"- Owner: {owner}")
        depends = []
        if comp.get("depends"):
            depends.extend(comp["depends"])
        if feature:
            for dep_feat in feature.get("deps", []):
                mapped_ids = feature_to_component_ids.get(dep_feat)
                if mapped_ids:
                    depends.extend(mapped_ids)
                else:
                    depends.append(feature_map.get(dep_feat, {}).get("name", dep_feat))
        depends_names = []
        for dep in merge_lists(depends):
            depends_names.append(id_to_name.get(dep, dep))
        if depends_names:
            lines.append("- Depends on:")
            for dep_name in depends_names:
                lines.append(f"  - {dep_name}")
        feature_topics = feature.get("topics", []) if feature else []
        signals = merge_lists(feature_topics, comp.get("signals", []))
        if signals:
            lines.append("- Signals & Telemetry:")
            for sig in signals:
                mark = ""
                if "*" not in sig and sig not in known_topics:
                    mark = " ⚠"
                lines.append(f"  - `{sig}`{mark}")
        interfaces = comp.get("interfaces", {})
        feature_interfaces = {
            "http": [],
            "read_models": feature.get("read_models", []) if feature else [],
            "topics": feature_topics,
            "env": feature.get("env", []) if feature else [],
        }
        if feature:
            for http in feature.get("http", []):
                method = (http.get("method") or "").upper()
                path = http.get("path", "")
                if method and path:
                    feature_interfaces["http"].append(f"{method} {path}")
                elif path:
                    feature_interfaces["http"].append(path)
        for key in INTERFACE_LABELS:
            vals = merge_lists(feature_interfaces.get(key, []), interfaces.get(key))
            if vals:
                label = INTERFACE_LABELS[key]
                lines.append(f"- {label}:")
                for val in vals:
                    mark = ""
                    if key == "topics" and "*" not in val and val not in known_topics:
                        mark = " ⚠"
                    lines.append(f"  - `{val}`{mark}")
        storage = comp.get("storage", [])
        if storage:
            lines.append("- Storage & Records:")
            for item in storage:
                lines.append(f"  - `{item}`")
        docs = comp.get("docs", [])
        if docs:
            lines.append("- References:")
            for entry in docs:
                path = entry.get("path") if isinstance(entry, dict) else entry
                if not path:
                    continue
                if path.startswith("docs/"):
                    rel = path[len("docs/"):]
                    lines.append(f"  - [{rel}](../{rel})")
                else:
                    lines.append(f"  - [{path}]({base}{path})")
        notes = comp.get("notes", [])
        if notes:
            lines.append("- Notes:")
            for note in notes:
                lines.append(f"  - {note}")
        lines.append("")
    if missing_features:
        missing = ", ".join(sorted(set(missing_features)))
        print(f"warning: components reference unknown features: {missing}", file=sys.stderr)
    return "\n".join(lines)


def main():
    try:
        doc = load_components()
    except Exception as exc:
        print(f"error: failed to read system components: {exc}", file=sys.stderr)
        return 2
    paths = []
    for comp in doc.get("components", []):
        for ref in comp.get("docs", []):
            if isinstance(ref, dict):
                path = ref.get("path")
            else:
                path = ref
            if path:
                paths.append(path)
    missing = check_paths_exist(paths)
    if missing:
        print("warning: missing references:\n  - " + "\n  - ".join(missing), file=sys.stderr)
    features = load_features()
    known_topics = parse_topics_rs()
    OUT_MD.parent.mkdir(parents=True, exist_ok=True)
    OUT_MD.write_text(render(doc, features, known_topics), encoding="utf-8")
    print(f"wrote {OUT_MD}")
    return 0


if __name__ == "__main__":
    sys.exit(main())
